---
permalink: /
title: "XAI group"
excerpt: "About me"
author_profile: true
excerpt: ' '
header:
  overlay_image: "banner1.png"
  og_image: "banner.png"
redirect_from: 
  - /about/
  - /about.html

# people:
#   - stein
#   - huang
#   - kitharidis
#   - wagner
#   - lamers
#   - long
#   - antonov
#   - winter
#   - zeiser
---

The XAI research group at LIACS focuses on explainable artificial intelligence research in the field of evolutionary computation and (time-series) machine learning.
Dr. Niki van Stein is leading the XAI group.

![Banner](../images/xpred8.png){:width="100%"}
*AI generated impression of explainable predictive maintenance.*

Dr. Niki van Stein is a researcher, heading the XAI group, which is part of the Natural Computing Cluster of LIACS, and manager of the applied data science lab. She received her PhD in Computer Science from Leiden University in 2018. Niki's research interest are in eXplainable AI for automated machine learning, global (Bayesian) optimization and neural architecture search. She mostly works on research with direct applications in industry, such as predictive maintenance, car and ship design optimization and schedule optimization.

Next to her research, Niki has founded several software solution-oriented companies such as [Emerald-IT – Custom software development](https://emerald-it.nl), and [Smartnotation – the smart meeting minutes application](https://smartnotation.com).

Niki van Stein is also a fantasy writer for Role playing games such as Dungeons &amp; Dragons, see for example [this published adventure at DMs Guild](https://www.dmsguild.com/product/434552/The-Pocket-Universe-of-the-Mad-Mage?affiliate_id=3933879). 

eXplainable Artificial Intelligence and eXplainable Optimization
===

In the fast-paced world of advanced technology, where complex algorithms and models make decisions that affect our lives on a daily basis, it is imperative to understand and trust the reasoning behind these automated systems.

Optimization algorithms drive efficiency, finding optimal solutions for complex problems in various domains. However, black-box optimization algorithms are complex to analyse and sometimes behave unexpectedly. Understanding how these heuristics traverse the search space, if they show any structural bias, and what kind of problems they can solve best and worst is imperative to better understand these algorithms and their components. This is also crucial when we aim to increase their performance or automatically select and configure an optimization algorithm on a given problem.

Machine learning has revolutionized industries by enabling automated decision-making based on patterns and correlations in vast amounts of data. Yet, as models become more sophisticated and intricate, they can become inscrutable, making it difficult to comprehend the reasoning behind their predictions. In critical domains such as healthcare, finance, and autonomous systems, the ability to explain why a particular decision was made is paramount. Explainable AI techniques empower users to trust and interpret the outcomes of machine learning models, ensuring accountability and promoting ethical practices.

Explainable AI not only enhances transparency but also brings numerous other benefits. It enables users to identify and mitigate biases present in the data or the model, safeguarding against discriminatory outcomes. It allows for better understanding of the limitations and constraints of optimization and machine learning algorithms, enabling users to set realistic expectations and make informed decisions. Furthermore, explainability fosters collaboration between humans and AI systems, as it facilitates effective communication and knowledge transfer.

In industry, explainable AI has significant implications for optimization and machine learning. In the realm of predictive maintenance, understanding the rationale behind the maintenance recommendations can lead to more efficient resource allocation and cost savings. In car and ship design optimization, explanations provide valuable insights into the design space, enabling engineers to refine their models and make informed decisions about trade-offs. In schedule optimization, transparency allows stakeholders to comprehend the scheduling decisions and adjust accordingly to optimize productivity.

Ultimately, explainable AI is not just about satisfying curiosity or appeasing regulatory requirements; it is about empowering humans to trust, collaborate, and make meaningful use of advanced algorithms. By embracing explainability, we unlock the true potential of optimization and machine learning, paving the way for safer, fairer, and more effective applications across industries. So let us champion explainable AI, fueling a future where technology and human intelligence work hand in hand, driving progress and achieving remarkable feats.

Project websites
---
See the following websites for additional information about research projects of Niki van Stein.

* [Cimplo](http://cimplo.nl/)
* [XAIPre](https://xaipre.leidenuniv.nl/)
* [AutoEC](https://autoec.eu/)
